<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="High-Quality Mesh Generation with 3D-Guided Reconstruction Model">
  <meta name="keywords" content="sparse view 3D reconstruction, 3D generation, 3D AIGC, reconstruction model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P5TW3NKDFW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-P5TW3NKDFW');
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://www.sudo.ai/">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            Related Research from SUDOAI (Hillbot)
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://one-2-3-45.github.io">
              One-2-3-45
            </a>
            <a class="navbar-item" href="https://github.com/SUDO-AI-3D/zero123plus">
              Zero123++
            </a>
            <a class="navbar-item" href="https://sudo-ai-3d.github.io/One2345plus_page/">
              One-2-3-45++
            </a>
            <a class="navbar-item" href="https://sarahweiii.github.io/meshlrm/">
              MeshLRM
            </a>
            <a class="navbar-item" href="https://chaoxu.xyz/sparp/">
              SpaRP
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-1 publication-title" >MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model
            </h2>
            <!-- <h2 class="subtitle is-size-3 publication-venue">Anonymous</h2> -->
            <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://cseweb.ucsd.edu/~mil070/">Minghua Liu</a><sup>*1,2†</sup>,</span>
            <span class="author-block">
              <a href="https://chong-zeng.com">Chong Zeng</a><sup>*3‡</sup>,</span>
            <span class="author-block">
              <a href="https://sarahweiii.github.io">Xinyue Wei</a><sup>1,2†</sup>,
            </span>
            <span class="author-block">
              <a href="https://rshi.top">Ruoxi Shi</a><sup>1,2†</sup>,
            </span>
            <span class="author-block">
              <a href="https://ootts.github.io">Linghao Chen</a><sup>2,3†</sup>,
            </span>
            <span class="author-block">
              <a href="https://chaoxu.xyz">Chao Xu</a><sup>2,4†</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=N1jzRPEAAAAJ&hl=en">Mengqi Zhang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.zhaoningwang.com">Zhaoning Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=cTGxuQQAAAAJ&hl=en&oi=ao">Xiaoshuai Zhang</a><sup>1,2†</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.liuisabella.com">Isabella Liu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://hongzhiwu.com">Hongzhi Wu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://cseweb.ucsd.edu//~haosu/">Hao Su</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>UC San Diego,</span>
            <span class="author-block"><sup>2</sup>Hillbot Inc.,</span>
            <span class="author-block"><sup>3</sup>Zhejiang University,</span>
            <span class="author-block"><sup>4</sup>UCLA,</span>
<!--             <span class="author-block"><sup>5</sup>University of Central Florida</span> -->
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">* Equal contribution.</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">† Work done during internship at Hillbot Inc.</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">‡ Work done during internship at UC San Diego.</span>
          </div>
          </div>
        </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://huggingface.co/spaces/sudo-ai/MeshFormer"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-desktop"></i>
                  </span>
                  <span>Demo</span>
                </a>
              </span>
              
            </div>

          </div>
      </div>
    </div>
  </section>


  <section class="hero is-light is-small">
    <div class="hero-body ">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%" loading="lazy">
              <source src="./static/videos/composite_0.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%" loading="lazy">
              <source src="./static/videos/composite_1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%" loading="lazy">
              <source src="./static/videos/composite_2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%" loading="lazy">
              <source src="./static/videos/composite_3.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <p class="text-block">
          MeshFormer reconstructs high-quality 3D textured meshes with fine-grained, sharp geometric details in a single
          feed-forward pass that takes just a few seconds. <FONT color=orange><b>MeshFormer can be trained using 8 H100
              GPUs for just 2 days, whereas concurrent works require more than one hundred.</b></FONT>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!--       <img src="./imgs/teaser.png" /> -->
      <!--       <p>
        MeshFormer reconstructs high-quality 3D textured meshes with fine-grained, sharp geometric details in a single feed-forward pass that takes just a few seconds. <FONT color=orange><b>MeshFormer can be trained using 8 H100 GPUs for just 2 days, whereas concurrent works require more than one hundred.</b></FONT>
      </p> -->
      <br>
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Open-world 3D reconstruction models have recently garnered significant attention. However, without
              sufficient 3D inductive bias, existing methods typically entail expensive training costs and struggle to
              extract high-quality 3D meshes. In this work, we introduce MeshFormer, a sparse-view reconstruction model
              that explicitly leverages 3D native structure, input guidance, and training supervision. Specifically,
              instead of using a triplane representation, we store features in 3D sparse voxels and combine transformers
              with 3D convolutions to leverage an explicit 3D structure and the projective bias. In addition to
              sparse-view RGB input, we require the network to take as input and generate corresponding normal maps. The
              input normal maps can be predicted by 2D diffusion models, significantly aiding in the guidance and
              refinement of the geometry's learning. Moreover, by combining Signed Distance Function (SDF) supervision
              with surface rendering, we directly learn to generate high-quality meshes without the need for complex
              multi-stage training processes. By incorporating these explicit 3D biases, MeshFormer can be trained
              efficiently and deliver high-quality textured meshes with fine-grained geometric details. It can also be
              integrated with 2D diffusion models to enable fast single-image-to-3D and text-to-3D tasks.
            </p>
            <br>
          </div>
        </div>
      </div>

      <h2 class="title is-3 has-text-centered">Method Overview</h2>
      <img src="./imgs/pipeline_green.png"/>
      <p> MeshFormer takes a sparse set of multi-view RGB and normal images as input, which can be estimated using existing 2D diffusion models. We utilize a 3D feature volume representation, and submodules Voxel Former and Sparse Voxel Former share a similar novel architecture, detailed in the gray region. We train MeshFormer in a unified single stage by combining mesh surface rendering and 512^3 SDF supervision. MeshFormer learns an additional normal texture, which can be used to further enhance the geometry and generate fine-grained sharp geometric details.
      </p>
      <br>
      <br>

      <h2 class="title is-3 has-text-centered">Single Image to 3D</h2>
      <!-- <img src="./imgs/comparison.png" /> -->
      <div class="tabs is-boxed is-centered">
        <ul>
          <li class="is-active" data-tab="lgm"><a>LGM</a></li>
          <li data-tab="crm"><a>CRM</a></li>
          <li data-tab="one2345"><a>One2345++</a></li>
          <li data-tab="tripoSR"><a>TripoSR</a></li>
          <li data-tab="instantmesh"><a>InstantMesh</a></li>
          <li data-tab="meshlrm"><a>MeshLRM</a></li>
        </ul>
      </div>

      <div class="container">
        <div id="meshlrm" class="content-tab">
          <video poster="" id="meshlrm" autoplay muted loop playsinline height="100%" loading="lazy">
            <source src="./static/videos/MeshLRM.mp4" type="video/mp4">
        </div>
        <div id="instantmesh" class="content-tab">
          <video poster="" id="instantmesh" autoplay muted loop playsinline height="100%" loading="lazy">
            <source src="./static/videos/InstantMesh.mp4" type="video/mp4">
        </div>
        <div id="one2345" class="content-tab">
          <video poster="" id="one2345" autoplay muted loop playsinline height="100%" loading="lazy">
            <source src="./static/videos/One2345pp.mp4" type="video/mp4">
        </div>
        <div id="tripoSR" class="content-tab">
          <video poster="" id="tripoSR" autoplay muted loop playsinline height="100%" loading="lazy">
            <source src="./static/videos/TripoSR.mp4" type="video/mp4">
        </div>
        <div id="crm" class="content-tab">
          <video poster="" id="crm" autoplay muted loop playsinline height="100%" loading="lazy">
            <source src="./static/videos/CRM.mp4" type="video/mp4">
        </div>
        <div id="lgm" class="content-tab is-active">
          <video poster="" id="lgm" autoplay muted loop playsinline height="100%" loading="lazy">
            <source src="./static/videos/LGM.mp4" type="video/mp4">
        </div>
      </div>
      <p> Qualitative Examples from the GSO dataset. Both the textured and textureless mesh renderings are shown. Please
        zoom in to examine details and mesh quality.
      </p>
      <br>
      <br>
      <h2 class="title is-3 has-text-centered">Application: Text to 3D</h2>
      <img src="./imgs/text23d.png"/>

      <br>
      <br>
      <h2 class="title is-3 has-text-centered">Geometry Enhancement</h2>
      <div style="text-align: center;">
        <img src="./imgs/enhancement_zoomed6.png" style="width: 60%;"/>
      </div>
      <p> We task MeshFormer with outputting an additional 3D normal map, which can be used for geometry enhancement and generating sharper geometric details. This is achieved by applying a traditional algorithm as a post-processing step that aligns the mesh vertices with the normals.
      </p>

    </div>
  </section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://huggingface.co/spaces/sudo-ai/MeshFormer" class="external-link" disabled>
        <i class="fa fa-desktop"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</body>

</html>